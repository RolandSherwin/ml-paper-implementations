{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602e0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gigadom.in/2020/04/18/deconstructing-convolutional-neural-networks-with-tensorflow-and-keras/\n",
    "#https://keras.io/examples/vision/visualizing_what_convnets_learn/\n",
    "#https://github.com/jalused/Deconvnet-keras/blob/master/Deconvnet-keras.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers as tfl\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c2f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ae2e3",
   "metadata": {},
   "source": [
    "- We need to use tf.keras.backened.function to execute one layer at a time. This gives us access to input/output values of each layer. We need the output values of the last layer to pass into the reversing layers. Where we each layer's output values are passed the the next layer up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10a5267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLayer():\n",
    "    \"\"\"Base Layer for all the Reverse Layers like DConv2D, DMaxPooling2D etc.,\n",
    "    \n",
    "    Arguments:\n",
    "    layer - A trained Layer object like Conv2D, Dense etc., \n",
    "    \"\"\"\n",
    "    def __init__(self, layer):\n",
    "        # We don't get the weights in the base class since layers like MaxPooling2D\n",
    "        # don't have weights.\n",
    "        self.layer = layer\n",
    "        # The below two are Keras.backend.function() which executes forward pass given the input and output layers\n",
    "        # These will be set by the child classes.\n",
    "        self.forward_function = None\n",
    "        self.reverse_function = None\n",
    "        \n",
    "    def forward_pass(self, data, learning_phase=0):\n",
    "        \"\"\"Computes the normal forward pass of an image through the network and returns the output\n",
    "        values of that layer.\n",
    "        \n",
    "        Arguments:\n",
    "        data - The output of the previous layer i.e., layer[i+1]\n",
    "        learning_phase - \n",
    "        \"\"\"\n",
    "        self.forward_data = self.forward_function(data)\n",
    "        return self.forward_data\n",
    "        \n",
    "    def reverse_pass(self, data, learning_phase=0):\n",
    "        \"\"\"Computes the reversing of each layer. For example reversing a Conv2D layer by\n",
    "        tranposing its weights(feature maps) in vertical and horizontal direction and then\n",
    "        executing Conv2D on the tranposed weights.\n",
    "        \n",
    "        Arguments:\n",
    "        \"\"\"\n",
    "        self.reverse_data = reverse_function(data)\n",
    "        return self.reverse_data\n",
    "\n",
    "class DInput(DLayer):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__(layer)\n",
    "    \n",
    "    # overriding the parent's method\n",
    "    def forward_pass(self, data, learning_phase=0):\n",
    "        self.forward_data = data\n",
    "        return self.forward_data\n",
    "    \n",
    "    def reverse_pass(self, data, learning_phase=0):\n",
    "        self.reverse_data = data\n",
    "        return self.reverse_data\n",
    "\n",
    "class DConv2D(DLayer):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, layer):\n",
    "        super().__init__(layer)\n",
    "        \n",
    "        weights = self.layer.get_weights() # a list containing the [weights, bias]\n",
    "        # weight shape = (filter_length, filter_breadth, filter_channels, # of filters)\n",
    "        # bias shape = (# of filters,) since we use 1 bias per filter.\n",
    "        W = weights[0]\n",
    "                \n",
    "        n_filters = W.shape[3]\n",
    "        kernel_size = (W.shape[1], W.shape[2])\n",
    "        # excluding first dimension which is batch_size; since we are gonna pass a single image only.\n",
    "        inputs = tf.keras.Input(shape=layer.input_shape[1:]) \n",
    "        output = tfl.Conv2D(filters=n_filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            padding='same',\n",
    "                            weights=weights)(inputs)\n",
    "        \n",
    "        self.forward_function = K.function(inputs, output)\n",
    "        \n",
    "        # Flip each filter horizontally and vertically\n",
    "        W = np.transpose(W, (0,1,3,2))\n",
    "        W = W[::-1, ::-1, :, :]\n",
    "        print(W.shape)\n",
    "        n_filters = W.shape[3]\n",
    "        kernel_size = (W.shape[1], W.shape[2])\n",
    "        b = np.zeros(n_filters)\n",
    "\n",
    "        inputs = tf.keras.Input(shape=layer.output_shape[1:])\n",
    "        output = tfl.Conv2D(filters=n_filters,\n",
    "                           kernel_size=kernel_size,\n",
    "                           padding='same',\n",
    "                           weights=[W,b])(inputs)\n",
    "        \n",
    "        self.reverse_function = K.function(inputs, output)\n",
    "        \n",
    "\n",
    "class DActivation(DLayer):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__(layer)\n",
    "        \n",
    "        self.activation = layer.activation\n",
    "#         inputs = tfl.\n",
    "                \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67f6b7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.engine.input_layer.InputLayer'>\n",
      "<class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "(3, 64, 3, 3)\n",
      "(3, 64, 3, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (64, 3, 64, 3) not compatible with provided weight shape (3, 64, 3, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-37978a8eb0b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mvisualize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-37978a8eb0b2>\u001b[0m in \u001b[0;36mvisualize_layer\u001b[0;34m(model, image, layer_name, max_activation_only)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mdeconv_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeconv_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-3fb8f0ec4fbe>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         output = tfl.Conv2D(filters=n_filters,\n\u001b[0m\u001b[1;32m     84\u001b[0m                            \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2720\u001b[0m           \u001b[0;31m# Using `init_scope` since we want variable assignment in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m           \u001b[0;31m# `set_weights` to be treated like variable initialization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2722\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2723\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0mref_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m           raise ValueError(\n\u001b[0m\u001b[1;32m   1872\u001b[0m               \u001b[0;34m'Layer weight shape %s not compatible with provided weight '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m               'shape %s' % (ref_shape, weight.shape))\n",
      "\u001b[0;31mValueError\u001b[0m: Layer weight shape (64, 3, 64, 3) not compatible with provided weight shape (3, 64, 3, 3)"
     ]
    }
   ],
   "source": [
    "def visualize_layer(model, image=None, layer_name=None, max_activation_only=False):\n",
    "    \"\"\"Visualize a single Layer\n",
    "    \"\"\"\n",
    "    deconv_layers = []\n",
    "    for layer in model.layers:\n",
    "        print(type(layer))\n",
    "        if isinstance(layer, tfl.InputLayer):\n",
    "            deconv_layers.append(DInput(layer))\n",
    "            \n",
    "        if isinstance(layer, tfl.Conv2D):\n",
    "            deconv_layers.append(DConv2D(layer))\n",
    "            print(deconv_layers)\n",
    "            break\n",
    "    \n",
    "    \n",
    "\n",
    "visualize_layer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c37e34f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "np.transpose(x, (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7db140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ml': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0597ef2c4e330346690cfc3eee48a64f4a5787db7dc7ff65ed373f1569f4e13ec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
